第十四章大型測試

’“”

在前幾章中，我們已經講述了測試文化是如何在建立的，以及小型單元測試是如何成爲開發人員工作流程的基本組成部分。那麼其他類型的測試呢？事實證明，確實使用了許多大型測試，這些測試構成了健康的軟件工程所需的風險緩解策略的重要組成部分。但是想要確保它們是有價值的資產而不是資源黑洞，那麼這些測試面臨了更多的挑戰。在這一章中，我們將討論什麼是大型測試，什麼時候執行這些測試，以及保持其有效性的最佳做法。

什麼是大型測試？

如前所述，谷歌對測試規模有特定的概念。小型測試僅限於單線程、單進程、單服務器。較大的測試沒有相同的限制。但谷歌也有測試範圍的概念。單元測試的範圍必然比集成測試的範圍小。而最大範圍的測試（有時被稱爲端到端或系統測試）通常涉及多個實際依賴項和較少的測試替身。（是在的文章中，提出了這個概念。雖然是年的文章了，但裏面的概念並不過時。這篇文章提到只是一個通用的詞，代表爲了達到測試目的並且減少被測試對象的依賴，使用“替身”代替一個真實的依賴對象，從而保證了測試的速度和穩定性。統一翻譯爲測試替代）

較大的測試有許多是小型測試所不具備的內容。它們受的約束不同；因此，它們可以表現出以下特徵：

它們可能很慢。我們的大型測試的默認時長時間爲分鐘或小時，但我們也有運行數小時甚至數天的測試。它們可能是不封閉的。大型測試可能與其他測試和流量共享資源。它們可能是不確定的。如果大型測試是非密封的，則幾乎不可能保證確定性：其他測試或用戶狀態可能會干擾它。

那麼，爲什麼要進行大型測試？回想一下你的編碼過程。你是如何確認你寫的程序真的能工作的？你可能邊寫邊運行單元測試，但你是否發現自己在運行實際的二進制文件並親自體驗？而當你與他人分享這些代碼時，他們是如何測試的呢？是通過運行你的單元測試，還是通過自己體驗？

’’’

另外，你怎麼知道你的代碼在升級時還能繼續工作？假設你有一個使用谷歌地圖的網站，有一個新的版本。你的單元測試很可能無法幫助你知道是否有任何兼容性問題。你可能會運行它，試一試，看看是否有什麼故障。

單元測試可以讓你對單個功能、對象和模塊有信心，但大型測試可以讓你對整個系統按預期工作更有信心。並且擁有實際的自動化測試能以手動測試無法比擬的方式擴展。

仿真度

大型測試存在的主要原因是爲了解決仿真度問題。仿真度是測試反映被測系統（）真實行爲的屬性。

一種設想仿真度的方法是在環境方面。如圖所示，單元測試將測試和一小部分代碼捆綁在一起作爲一個可運行的單元，這確保了代碼得到測試，但與生產代碼的運行方式有很大不同。產品本身才是測試中仿真度最高的環境。也有一系列的臨時選項。大型測試的一個關鍵是要找到適當的契合點，因爲提高仿真度也伴隨着成本的增加和（在線上的情況下）故障風險的增加。

圖環境仿真度遞增的尺度

“”

測試也可以用測試內容對現實的仿真度程度來衡量。如果測試數據本身看起來不真實，許多手工配置的大型測試就會被工程師摒棄。從生產中複製的測試數據仿真度更高（以這種方式捕獲），但一個很大的挑戰是如何在啓動新代碼之前創建真實的測試流量。這在人工智能（）中尤其是一個問題，因爲種子數據經常受到內在偏見的影響。而且，由於大多數單元測試的數據是手工配置的，它涵蓋的案例範圍很窄，並傾向於符合作者的偏見。數據所遺漏的場景代表了測試中的仿真度差距。

單元測試中常見的問題

如果較小的測試失敗，也可能需要進行較大的測試。下面的小節介紹了單元測試無法提供良好風險緩解覆蓋一些特定領域的示例。

仿真度不足的測試替代

一個單元測試通常覆蓋一個類或模塊。測試替代（如第章所討論的）經常被用來消除重量級或難以測試的依賴項。但是當這些依賴關係被替換時，就有可能出現替換後的東西和被替換的東西不匹配·的情況。

在谷歌，幾乎所有的單元測試都是由編寫被測單元的工程師編寫的。當這些單元測試需要替代時，當使用的替代是模擬時，是編寫單元測試的工程師在定義模擬和它的預期行爲。但該工程師通常沒有寫被模擬的東西，因此可能對其實際行爲有誤解。被測單元與給定對等方之間的關係是一種行爲契約，如果工程師對實際行爲有誤解，則對契約的理解無效。

此外，模擬會變得過時。如果實際實現的作者看不到這個基於模擬的單元測試，並且實際實現發生了變化，那麼就沒有信號表明應該更新測試（以及正在測試的代碼）以跟上變化。

請注意，正如在第章中提到的，如果團隊爲他們自己的服務提供模擬，這種擔憂大多會得到緩解。

配置問題

單元測試涵蓋了給定二進制中的代碼。但該二進制文件在如何執行方面通常不是完全自洽的。通常情況下，二進制文件有某種部署配置或啓動腳本。此外，真正爲終端用戶服務的生產實例有它們自己的配置文件或配置數據庫。

如果這些文件存在問題，或者這些存儲定義的狀態與有問題的二進制文件之間存在兼容性問題，則可能會導致重大的用戶故障。單元測試不能驗證這種兼容性。順便說一下，這是一個很好的理由，確保你的配置和你的代碼一樣在版本控制中，因爲這樣，配置的變更可以被識別爲的來源，而不是引入隨機的外部碎片，並且可以在大型測試中構建。

在谷歌，配置變更是我們重大故障的頭號原因。這是一個我們表現不佳的領域，並導致了我們一些最尷尬的錯誤。例如，年，由於一次從未測試過的糟糕網絡配置推送，谷歌出現了一次全球停機。它們通常也比二進制文件具有更快的生產部署週期，而且它們可能更難測試。所有這些都會導致更高的失敗可能性。但至少在這種情況下（和其他情況下），配置是由版本控制的，我們可以快速識別故障並緩解問題。

>“”>>有關更多信息，請參見第頁和第章的“連續交付”。

高負載導致的問題

在谷歌，單元測試的目的是小而快，因爲它們需要適配標準測試執行基礎設施，也可以作爲順暢的開發人員工作流程的一部分多次運行。但性能、負載和壓力測試往往需要向一個特定的二進制文件發送大量的流量。這些流量在典型的單元測試模型中變得難以製造。而我們的大流量是很大的，往往是每秒數千或數百萬次的查詢（在廣告的情況下，實時競價）

非預期的行爲、投入和副作用

單元測試受到編寫它們的工程師想象力的限制。也就是說，他們只能測試預期的行爲和輸入。然而，用戶在產品中發現的問題大多是未預料到的（否則，他們不太可能將其作爲問題提交給最終用戶）。這一事實表明，需要不同的測試技術來測試非預期的行爲。

’

海勒姆定律在這裏是一個重要的考慮因素：即使我們可以測試是否符合嚴格的規定合同，有效的用戶合同也適用於所有可見的行爲，而不僅僅是規定的合同。單元測試不太可能單獨測試公共中未指定的所有可視行爲。

“”突發行爲和真空效應

單元測試僅限於它們所覆蓋的範圍內（特別是隨着測試替代的廣泛使用），因此如果超過此範圍發生行爲變化，則無法檢測到。由於單元測試被設計爲快速可靠，它們設計成屏蔽外界的副作用及噪聲：比如真實依賴、網絡和數據。單元測試就像理論物理中的一個問題：運行在真空中，巧妙地隱藏在現實世界的混亂中，這有助於提高速度和可靠性，但忽略了某些缺陷類別。

爲什麼不進行大型測試？

在前面的章節中，我們討論了對開發者友好的測試的許多特性。特別是，它需要做到以下幾點：可靠的它不能是不確定的，它必須提供一個有用的通過失敗信號。快速它需要足夠快，以避免中斷開發人員的工作流程。可擴展性谷歌需要能夠有效地運行所有這些有用的受影響的測試，用於預提交和後提交。

好的單元測試展現出這些特性。大型測試經常違反這些限制。例如，大型測試往往是脆弱的，因爲它們比小單元測試使用更多的基礎設施。它們的設置和運行速度也往往慢得多。而且，由於資源和時間的要求，它們在擴展上有困難，但往往也因爲它們不是孤立的這些測試可能會相互衝突。

此外，大型測試還帶來了另外兩個挑戰。首先，所有權是一個挑戰。單元測試顯然由擁有單元的工程師（和團隊）擁有。較大的測試跨越多個單元，因此可以跨越多個所有者。這帶來了一個長期的所有權挑戰：誰負責維護測試，誰負責在測試中斷時診斷問題？沒有明確的所有權，測試就會腐化。

’

大型測試的第二個挑戰是標準化問題（或缺乏標準化）。與單元測試不同，大型測試在編寫、運行和調試的基礎設施和流程方面缺乏標準化。大型測試的方法是系統架構設計的產物，因此在所需的測試類型中引入了差異性。例如，我們在谷歌廣告中建立和運行差異迴歸測試的方式與在搜索後端建立和運行此類測試的方式完全不同，而搜索後端又與雲存儲不同。他們使用不同的平臺，不同的語言，不同的基礎設施，不同的庫，以及相互競爭的測試框架。

’

這種缺乏標準化的情況有很大的影響。因爲大型測試有許多運行方式，在大規模的變更中，它們經常被忽略。見第章基礎設施沒有一個標準的方式來運行這些測試，要求執行的人員瞭解每個團隊測試的本地細節是不可行的。因爲更大的測試在各個團隊的實施中是不同的，因此實際測試這些團隊之間集成的測試需要統一不兼容的基礎架構。而且由於缺乏標準化，我們無法向（新的）甚至更有經驗的工程師傳授統一的方法，這既使情況長期存在，也導致人們對這種測試的動機缺乏瞭解。

谷歌的大型測試

“”

當我們在前面討論的測試歷史時（見第章），我們討論了（）如何在年強制執行自動化測試，以及這是一個分水嶺時刻。然而，在這之前，我們實際上已經有了自動化測試的使用，但一個普遍的做法是使用自動化的大型測試。例如，早在年就創建了一個端到端的測試來驗證產品方案。同樣，在年，搜索部門爲其索引代碼寫了一個類似的迴歸測試，而（當時甚至還沒有公開推出）在的測試上創造了它的變種。

“”“”

其他較大的測試模式也開始於年左右。谷歌搜索前端在很大程度上依賴於手動質量檢查端到端的測試場景的手動版本。得到了它的本地演示環境的版本一個腳本，在本地建立一個端到端的環境，其中有一些生成的測試用戶和郵件數據，用於本地手動測試。

’

當（我們的第一個持續構建框架）推出時，它並沒有區分單元測試和其他測試，但有兩個關鍵的進展導致了區分兩者。首先，專注於單元測試，因爲我們想鼓勵金字塔式測試，並確保絕大部分的測試是單元測試。第二，當取代成爲我們正式的持續構建系統時，它只能爲符合資格要求的測試服務：可在一次修改中構建的密封測試，可在最大時間限制內運行在我們的構建測試集羣上。儘管大多數單元測試滿足了這一要求，但大型測試大多不滿足。然而，這並沒有阻止對其他類型的測試的需求，而且它們一直在填補覆蓋率的空白。甚至堅持了多年，專門處理這些類型的測試，直到更新的系統取代它。

大型測試與時間

在本書中，我們一直在關注時間對軟件工程的影響，因爲谷歌已經開發了運行多年的軟件。大型測試是如何受到時間維度的影響的？我們知道，代碼的生命週期越長，某些活行爲就越有意義，各種形式的測試是一種在各個層面都有意義的活動，但適合的測試類型會隨着代碼的生命週期而改變。

正如我們之前所指出的，單元測試對於生命週期在幾小時以上的軟件開始有意義。在分鐘級別（小型腳本），手動測試是最常見的，通常在本地運行，但本地很可能就是產品，特別是對於一次性的腳本、演示或實驗。在更長的生命期，手動測試繼續存在，但通常是有差別的，因爲生產實例通常是雲託管而不是本地託管。

其餘大型測試都爲生命週期較長的軟件提供了價值，但隨着時間的增加，主要的問題變成了這種測試的可維護性。

“”

順便說一句，這一時間衝擊可能是開發“冰淇淋筒”測試反模式的原因之一，如第章所述，圖再次顯示

’

當開發從手動測試開始時（當工程師認爲代碼只能持續幾分鐘時），那些手動測試就會積累起來並主導最初的整體測試組合。例如，通常我們會修改腳本或應用程序並通過運行來驗證修改有效，然後繼續向其添加功能並通過手動運行來測試它，這是非常典型的。長此以往，原型產品的功能會越來越完整，直至可與其他人共享，但實際上不存在針對它的自動測試。

“”

更糟糕的是，如果代碼很難進行單元測試（因爲它最初的實現方式），那麼唯一可以編寫的自動化測試就是端到端的測試，並且我們在幾天內無意中創建了“遺留代碼”。

在開發的頭幾天，通過建立單元測試，向金字塔式測試邁進，然後在這之後通過引入自動化集成測試，擺脫手動端到端的測試，這對長期的穩定是至關重要的。我們成功地使單元測試成爲提交的要求，但彌補單元測試和手工測試之間的差距對長期穩健是必要的。

谷歌規模的大型測試

在軟件規模較大的情況下，大型測試似乎更有必要，也更合適，但即使如此，編寫、運行、維護和調試這些測試的複雜性也會隨着規模的增長而增加，複雜度遠超過單元測試。

在由微服務或獨立服務器組成的系統中，互連模式看起來像一個圖：讓該圖中的節點數爲我們的。每次向該圖添加新節點時，都會對通過該圖的不同執行路徑的數量產生乘法效應的倍增。

圖描繪了一個想象中的：這個系統由一個有用戶的社交網絡、一個社交圖、一個流和一些混合廣告組成。廣告由廣告商創建，並在社交流的背景下提供服務。這個單獨由兩組用戶、兩個、三個數據庫、一個索引管道和六個服務器組成。圖中列舉了條邊。測試所有端到端的可能性已經很困難了。想象一下，如果我們在這個組合中添加更多的服務、管道和數據庫：照片和圖像、機器學習照片分析等等？

以端到端的方式測試的不同場景的速率可以指數增長或組合增長，這取決於被測系統的結構，並且這種增長無法擴展。因此，隨着系統的發展，我們必須找到其他大型測試的測試策略，以保持測試的可管理性。

’

然而，由於實現這一規模所需的決策，此類測試的價值也增加了。這是仿真度的一個影響：隨着我們向更大的層軟件發展，如果服務的仿真度加倍（），那麼當把所有的服務放在一起時，出現錯誤的幾率是的指數。再看看這個例子，如果我們用測試替代來取代用戶服務器和廣告服務器，並且這些測試替代的仿真度較低（例如，的不準確度），出現錯誤的可能性爲（（這只是兩個低仿真度的替代。

因此，以在這種規模下工作良好但保持合理高仿真度的方式實現更大的測試變得至關重要。

提示：儘可能小的測試

即便是集成測試，也是越小越好少數大型測試比一個超大測試要好。而且，因爲測試的範圍經常與的範圍相聯繫，找到使變小的方法有助於使測試變小。

當出現一個需要許多內部系統服務的用戶請求時，實現這種測試比率的一種方法是連鎖測試，如圖所示，不是具體執行，而是創建多個較小的成對集成測試，代表整個場景。

大型測試組成

儘管大型測試不受小型測試約束的約束，並且可以由任何內容組成，但大多數大型測試都顯示出共同的模式。大型測試通常由具有以下階段的流程組成：

獲得被測試的系統必要的測試數據使用被測系統執行操作驗證行爲

被測試的系統

大型測試的一個關鍵組成部分是前述的（見圖）。一個典型的單元測試將關注點集中在一個類或模塊上。此外，測試代碼運行在與被測試代碼相同的進程（或虛擬機，在的情況下）。對於大型測試，通常是非常不同的；一個或多個獨立的進程，測試代碼通常（但不總是）在自己的進程中。

’’

在谷歌，我們使用許多不同形式的，而的範圍是大型測試本身範圍的主要驅動因素之一（越大，測試越大）。每種形式都可以根據兩個主要因素來判斷。封閉性這是與相關測試之外的其他組件的使用和交互的隔離。具有高隔離性的將具有最少的併發性和基礎架構脆弱性來源。仿真度反映被測生產系統的準確性。具有高仿真度的將由與生產版本相似的二進制文件組成（依賴於類似的配置，使用類似的基礎設施，並且具有類似的總體拓撲）。

“”“”“”’

通常有這兩個因素是直接衝突的。以下是一些的例子：

單進程整個被測系統被打包成一個二進制文件（即使在生產中這些是多個獨立的二進制文件）。此外，測試代碼可以被打包成與相同的二進制文件。如果所有測試都是單線程的，那麼這種測試組合可能是一個“小”測試，但它對生產拓撲和配置仿真度最低。單機被測系統由一個或多個獨立的二進制文件組成（與生產相同），測試是自身的二進制文件。但一切都在一臺機器上運行。這用於中等測試。理想情況下，在本地運行這些二進制文件時，我們使用每個二進制文件的生產啓動配置，以提高仿真度。多機被測系統分佈在多臺機器上（很像生產雲部署）。這比單機的仿真度還要高，但它的使用使得測試的規模很大，而且這種組合很容易受到網絡和機器脆弱程度的影響。共享環境（預發和生產）測試只使用共享環境，而不是運行獨立的。這具有最低的成本，因爲這些共享環境通常已經存在，但是測試可能會與其他同時使用衝突，並且必須等待代碼被推送到這些環境中。生產也增加了最終用戶受到影響的風險。混合模式一些代表了一種混合：可以運行一些，但可以讓它與共享環境交互。通常被測試的東西是顯式運行的，但是它的後端是共享的。對於像谷歌這樣擴張的公司來說，實際上不可能運行所有谷歌互聯服務的多個副本，因此需要一些混合。

封閉式的好處

大型測試中的可能是不可靠性和長運行時間的主要原因。例如，生產中的測試使用實際的生產系統部署。如前所述，這很流行，因爲沒有額外的環境開銷成本，但在代碼到達生產環境之前，生產測試無法運行，這意味着這些測試本身無法阻止將代碼發佈到生產環境本質上太晚了。

“”

最常見的第一種選擇是創建一個巨大的共享預發環境並在那裏運行測試。這通常是作爲某些發佈升級過程的一部分來完成的，但它再次將測試執行限制爲僅當代碼可用時。作爲一個替代方案，一些團隊允許工程師在預發環境中保留時間，並使用該時間窗口來部署待定的代碼和運行測試，但這並不能隨着工程師數量的增加或服務數量的增加而擴展，因爲環境、用戶數量和用戶衝突的可能性都會迅速增加。

下一步是支持雲隔離的或機器密閉的。這樣的環境通過避免代碼發佈的衝突和保留要求來改善情況。

案例研究：生產中的測試風險和

我們提到，在生產中進行測試是有風險的。我們需要一種方法來驗證生產中的視頻渲染是否正常，因此創建了自動腳本來生成測試視頻，上傳它們，並驗證上傳質量，這是在谷歌擁有的名爲的中進行的。

後來，這個渠道在《連線》雜誌的一篇文章中被公佈，這導致它在媒體上傳播，隨後人們努力解開這個謎團。最後，我們通過與它進行一些互動，包括一個和一個復活節彩蛋，所以一切都很順利。但我們確實需要考慮最終用戶發現我們在生產中包含的任何測試數據的可能性並做好準備。

減少問題邊界內的範圍

有一些特別痛苦的測試界限，值得避免。同時涉及前臺和後臺的測試變得很痛苦，因爲用戶界面（）測試是出了名的不可靠和高成本：的外觀和感覺方式經常發生變化，使測試變得脆弱，但實際上不會影響底層行爲。通常具有難以測試的異步行爲。

儘管對服務的進行端到端測試非常有用，但這些測試會增加和後端的維護成本。相反，如果後端提供公共，則通常更容易在邊界將測試拆分爲連接的測試，並使用公共驅動端到端測試。無論是瀏覽器、命令行界面（）、桌面應用程序還是移動應用程序，都是如此。

另一個特殊的邊界是第三方依賴關係。第三方系統可能沒有用於測試的公共共享環境，在某些情況下，向第三方發送流量會產生成本。因此，不建議讓自動匹配的測試使用真正的第三方，並且依賴性是分割測試的一個重要接點。

爲了解決規模問題，我們通過用內存數據庫替換它的數據庫，並移除範圍之外的一個我們真正關心的服務器，使這個變得更小，如圖所示。這個更可能適合在一臺機器上使用。

“”

關鍵是要確定仿真度和成本可靠性之間的權衡，並確定合理的邊界。如果我們能夠運行少量的二進制文件和一個測試，並將其全部打包到進行常規編譯、鏈接和單元測試執行的同一臺機器上，我們就能爲我們的工程師提供最簡單、最穩定的集成測試。

錄製重放代理

在前一章中，我們討論了測試加倍和可用於將被測類與其難以測試的依賴項解耦的方法。我們還可以通過使用具有等效的模擬、打樁或僞服務器或進程來複制整個服務器和進程。然而，無法保證所使用的測試替代實際上符合其所替換的真實對象的契約。

’’’’

處理的依賴關係和附屬服務的一種方法是使用測試替代，但如何知道替代反映了依賴的實際行爲？在谷歌之外，一種正在發展的方法是使用一個框架進行消費者驅動的合同測試。這些測試爲客戶和服務的提供者定義了一個合同，這個合同可以驅動自動測試。也就是說，一個客戶定義了一個服務的模擬，說對於這些輸入參數，我得到一個特定的輸出。然後，真正的服務在真正的測試中使用這個輸入輸出對，以確保它在這些輸入的情況下產生那個輸出。消費者驅動的合同測試的兩個公共工具是和。谷歌對的嚴重依賴意味着我們內部不使用這些工具。

“”“”

在谷歌，我們做的有些不同。我們最流行的方法（有公共）是使用較大的測試生成較小的測試，方法是在運行較大的測試時錄製到這些外部服務的流量，並在運行較小的測試時重放流量。大型或“記錄模式”測試在提交後持續運行，但其主要目的是生成這些流量日誌（但必須通過才能生成日誌）。在開發和提交前測試過程中，使用較小的或“重放模式”測試。

錄製重放工作原理的一個有趣方面是，由於非終結性，必須通過匹配器匹配請求，以確定重放的響應。這使得它們與打樁和模擬非常相似，因爲參數匹配用於確定結果行爲。

新測試或客戶端行爲發生顯著變化的測試會發生什麼情況？在這些情況下，請求可能不再與錄製的流量文件中的內容匹配，因此測試無法在重放模式下通過。在這種情況下，工程師必須以記錄模式運行測試以生成新的通信量，因此使運行錄製測試變得簡單、快速和穩定非常重要。

測試數據

測試需要數據，大型測試需要兩種不同的數據：

種子數據預先初始化到被測系統中的數據，反映測試開始時的狀態測試流量在測試執行過程中，由測試本身發送至被測系統的數據。

由於獨立的和更大的的概念，狀態的種子工作往往比單元測試中的設置工作要複雜得多。比如說：領域數據一些數據庫包含預先填充到表中的數據，並作爲環境的配置使用。如果不提供領域數據，使用這種數據庫的實際服務二進制文件可能在啓動時失敗。現實的基線要使被認爲是現實的，它可能需要在啓動時提供一組現實的基礎數據，包括質量和數量。例如，社交網絡的大型測試可能需要一個真實的社交圖作爲測試的基本狀態：必須有足夠多的具有真實配置文件的測試用戶以及這些用戶之間的足夠互聯，才能接受測試。種子數據種子的可能很複雜。也許可以直接寫入數據存儲，但這樣做可能會繞過由執行寫入的實際二進制文件執行的觸發器和檢查。

“”

數據可以通過不同的方式產生，比如說以下幾種：

手工製作數據與小型測試一樣，我們可以手動創建大型測試的測試數據。但是在一個大型中爲多個服務設置數據可能需要更多的工作，並且我們可能需要爲大型測試創建大量數據。複製的數據我們可以複製數據，通常來自生產。例如，我們可以通過從生產地圖數據的副本開始測試地球地圖，以提供基線，然後測試我們對它的更改。抽樣數據複製數據可以提供太多的數據來進行合理的工作。採樣數據可以減少數量，從而減少測試時間，使其更容易推理。智能抽樣包括複製最小的數據以達到最大覆蓋率的技術。

驗證

在運行並向其發送流量後，我們仍然必須驗證其行爲。有幾種不同的方法可以做到這一點

手動就像你在本地嘗試你的二進制文件一樣，手動驗證使用人工與互動以確定它的功能是否正確。這種驗證可以包括通過執行一致的測試計劃中定義的操作來測試迴歸，也可以是探索性的，通過不同的交互路徑來識別可能的新故障。需要注意的是，人工迴歸測試的規模化不是線性的：系統越大，通過它的操作越多，需要人力測試的時間就越更多。斷言與單元測試一樣，這些是對系統預期行爲的明確檢查。例如，對於谷歌搜索的集成測試，一個斷言可能如下：

測試（差異）測試不是定義顯式斷言，而是運行的兩個副本，發送相同的數據，並比較輸出。未明確定義預期行爲：人工必須手動檢查差異，以確保任何預期更改。

大型測試的類型

我們現在可以將這些不同的方法組合到、數據和斷言中，以創建不同類型的大型測試。然後，每項測試都有不同的特性，可以降低哪些風險；編寫、維護和調試它需要多少工作了；以及它在運行資源方面的成本。

下面是我們在谷歌使用的各種大型測試的列表，它們是如何組成的，它們的用途是什麼，它們的侷限性是什麼：

一個或多個二進制文件的功能測試瀏覽器和設備測試性能、負載和壓力測試部署配置測試探索性測試對比（迴歸）測試用戶驗收測試（）探針和金絲雀分析故障恢復和混沌工程用戶評價

考慮到如此廣泛的組合和如此廣泛的測試，我們如何管理做什麼以及何時做？軟件設計的一部分是起草測試計劃，而測試計劃的一個關鍵部分是需要什麼類型的測試以及每種測試需要多少的戰略大綱。該測試策略確定了主要風險向量和緩解這些風險向量的必要測試方法。

“”

在谷歌，我們有一個專門的工程角色“測試工程師”，我們在一個好的測試工程師身上尋找的東西之一就是能夠爲我們的產品勾勒出一個測試策略。

一個或多個二進制文件的功能測試

此類試驗具有以下特點：

：單機密封或雲部署隔離數據：手工製作覈查：斷言

到目前爲止，我們已經看到，單元測試無法以真正仿真地測試複雜的系統，僅僅是因爲它們的打包方式與實際代碼的打包方式不同。許多功能測試場景與給定二進制文件的交互方式不同於與該二進制文件中的類的交互方式，這些功能測試需要單獨的，因此是經典的大型測試。

毫不奇怪，測試多個二進制文件的相互作用甚至比測試單個二進制文件更復雜。一個常見的案例是在微服務環境中，當服務被部署爲許多獨立的二進制文件。在這種情況下，功能測試可以通過提出由所有相關二進制文件組成的，並通過發佈的與之交互，來覆蓋二進制文件之間的真實交互。

瀏覽器和設備測試

測試和移動應用程序是對一個或多個交互二進制文件進行功能測試的特例。可以對底層代碼進行單元測試，但對於最終用戶來說，公共是應用程序本身。將測試作爲第三方通過其前端與應用程序交互提供了額外的覆蓋層。

性能、負載和壓力測試

此類試驗具有以下特點：

：雲部署隔離數據：手工製作或從生產中多路傳輸驗證：差異（性能指標）

儘管可以在性能、負載和壓力方面測試較小的單元，但此類測試通常需要同時向外部發送通信量。該定義意味着此類測試是多線程測試，通常在被測二進制文件的範圍內進行測試。但是，這些測試對於確保版本之間的性能不會下降以及系統能夠處理預期的流量峯值至關重要。

“”

隨着負載測試規模的增長，輸入數據的範圍也在增長，甚至很難在負載下生成觸發所需的負載規模。負載和壓力處理是系統的高度湧現屬性；也就是說，這些複雜的行爲屬於整個系統，而不是個別組成。因此，重要的是使這些測試看起來儘可能地接近生產。每個所需的資源與生產所需的資源類似，因此很難緩解生產拓撲中的噪音。

消除性能測試中的噪音的一個研究領域是修改部署拓撲結構各種二進制文件在機器網絡中的分佈。運行二進制文件的機器會影響性能特性；因此，如果在性能差異測試中，基本版本在快速機器（或具有高速網絡的機器）上運行，而新版本在慢速機器上運行，則可能會出現性能迴歸。此特性意味着最佳部署是在同一臺機器上運行兩個版本。如果一臺機器無法同時安裝兩種版本的二進制文件，另一種方法是通過執行多次運行並消除峯值和谷值來進行校準。

部署配置測試

’

此類試驗具有以下特點：

：單機封閉或雲部署隔離數據：無驗證：斷言（不會崩潰）

很多時候，缺陷的根源不是代碼，而是配置：數據文件、數據庫、選項定義等等。較大的測試可以測試與其配置文件的集成，因爲這些配置文件是在給定二進制文件啓動期間讀取的。

這種測試實際上是的冒煙測試，不需要太多額外的數據或驗證。如果成功啓動，則測試通過。否則，測試失敗。

探索性測試

此類試驗具有以下特點：

：生產或共享預發數據：生產或已知測試範圍覈查：手動

探索性測試是一種手動測試，它的重點不是通過重複已知的測試流程來尋找已知行爲的迴歸測試，而是通過嘗試新的用戶場景來尋找有問題的行爲。訓練有素的用戶測試人員通過產品的公共與產品交互，在系統中尋找新的路徑，尋找行爲偏離預期或直觀行爲的路徑，或者是否存在安全漏洞。

“”

探索性測試對於新系統和已發佈系統都很有用，可以發現意外行爲和副作用。通過讓測試人員在系統中遵循不同的可到達路徑，我們可以增加系統覆蓋率，並且當這些測試人員發現時，可以捕獲新的自動化功能測試。在某種意義上，這有點像功能集成測試的手動“模糊測試”版本。

>>>詹姆斯·惠塔克，探索性軟件測試：提示，詭計，旅行，和技巧到指導測驗設計（紐約：，年）。

侷限性

手動測試無法進行亞線性擴展；也就是說，執行手動測試需要人工時間。通過探索性測試發現的任何缺陷都應該通過能夠更頻繁地運行的自動化測試進行復制。

掃除

“”

我們用於手動探索性測試的一種常見方法是大掃除。一組工程師和相關人員（經理、產品經理、測試工程師、熟悉產品的任何人）安排了一次“會議”，但在此情況下，所有相關人員都會手動測試產品。對於大掃除的特定關注領域和或使用系統的起點，可能會有一些已發佈的指南，但目標是提供足夠的交互多樣性，以記錄有問題的產品行爲和底層的。

對比測試

此類試驗具有以下特點：

：兩個雲部署的隔離環境數據：通常從生產或取樣中多路傳輸驗證：差異比較

’

單元測試覆蓋了一小部分代碼的預期行爲路徑。但是，對於給定的面向公衆的產品，預測多種可能的故障模式是不可行的。此外，正如海勒姆定律所指出的，實際的公共不是聲明的，而是一個產品的所有用戶可見的方面。鑑於這兩個特性，對比測試可能是谷歌最常見的大型測試形式，這並不奇怪。這種方法在概念上可以追溯到年。在谷歌，我們從年開始爲我們的大多數產品進行基於這種模式的測試，從廣告、搜索和地圖開始。

對比測試通過向公共發送流量並比較新舊版本之間的響應（特別是在遷移期間）。任何行爲上的偏差都必須作爲預期的或未預期的（迴歸）進行調整。在這種情況下，由兩組真實的二進制文件組成：一個運行在候選版本，另一個運行在基本版本。第三個二進制程序發送流量並比較結果。

還有其他的變體。我們使用測試（將系統與自身進行比較）來識別非決定性行爲、噪音和脆弱性，並幫助從差異中去除這些東西。我們有時也會使用測試，比較最後的生產版本、基線構建和一個待定的變化，以便一眼就能看出即時更改的影響，以及下一個發佈版本的累積影響。

差異測試是一種低成本但可自動檢測任何已啓動系統意外副作用的方法。

侷限性

對比測試確實帶來了一些需要解決的挑戰：

批准必須有人對結果有足夠的瞭解，才能知道是否會出現任何差異。與典型的測試不同，不清楚差異是好是壞（或者基線版本實際上是否有效），因此在這個過程中通常需要手動步驟。噪音對於對比測試來說，任何在結果中引入意料之外的噪音都會導致對結果進行更多的手動查驗。有必要對噪聲進行補救，這也是建立一個好的對比測試的一個很大的複雜性來源。覆蓋率爲對比測試產生足夠的有用流量是一個具有挑戰性的問題。測試數據必須涵蓋足夠多的場景，以確定角落的差異，但很難手動管理這樣的數據。配置配置和維護一個是相當具有挑戰性的。一次創建兩個可以使複雜性加倍，特別是如果這些共享相互依賴關係。

此類試驗具有以下特點：

：機器密封或雲部署隔離數據：手工製作覈查：斷言

“”“”

單元測試的一個關鍵方面是，它們是由編寫被測代碼的開發人員編寫的。但是，這使得對產品的預期行爲的誤解很可能不僅反映在代碼中，而且也反映在單元測試中。這樣的單元測試驗證了代碼是按實現工作而不是按預期工作。

“”

對於有特定終端客戶或客戶代理（客戶委員會甚至產品經理）的情況，是通過公共執行產品的自動化測試，以確保特定用戶旅程的總體行爲符合預期。存在多個公共框架（例如，和），使這種測試可以用用戶友好的語言寫讀，通常是在可運行規範的背景下。

’

谷歌實際上並沒有做很多自動化的，也不怎麼使用規範語言。谷歌的許多產品在歷史上都是由軟件工程師自己創建的。幾乎不需要可運行的規範語言，因爲那些定義預期產品行爲的規範語言通常能夠流利地使用實際的編碼語言。

探針和金絲雀分析

此類試驗具有以下特點：

：生產數據：生產驗證：斷言和差異（度量）

探針和金絲雀分析是確保生產環境本身健康的方法。在這些方面，它們是生產監控的一種形式，但在結構上與其他大型測試非常相似。

“”

是功能測試，針對生產環境運行編碼的斷言。通常，這些測試執行衆所周知的和確定的只讀動作，這樣即使生產數據隨時間變化，斷言也能成立。例如，探針可能在執行谷歌搜索，並驗證返回的結果，但實際上並不驗證結果的內容。在這方面，它們是生產系統的冒煙測試，但可以及早發現重大問題。

金絲雀分析也是類似的，只不過它關注的是一個版本何時被推送到生產環境。如果發佈是分階段進行的，我們可以同時運行鍼對升級（金絲雀）服務的探針斷言，以及比較生產中金絲雀和基線部分的健康指標，並確保它們沒有失衡。

探針應該在任何實時系統中使用。如果生產推廣過程包括一個階段，其中二進制文件被部署到生產機器的有限子集（一個金絲雀階段），則金絲雀分析應該在該過程中使用。

侷限性

此時（生產中）發現的任何問題都已經影響到最終用戶。

如果探針執行可變（寫入）操作，它將修改生產狀態。這可能導致以下三種結果之一：不確定性和評估失敗、未來寫入能力失敗或用戶可見的副作用。

故障恢復與混沌工程

此類試驗具有以下特點：

：生產數據：生產和用戶定製（故障注入）驗證：手動和對比（指標）

這些測試將測試系統對意外更改或故障的反應。

多年來，谷歌每年都會舉辦一場名爲“災難恢復測試”的演練，在這場演練中，故障幾乎以全球規模注入我們的基礎設施。我們模擬了從數據中心火災到惡意攻擊的一切。在一個令人難忘的案例中，我們模擬了一場地震，將我們位於加州山景城的總部與公司其他部門完全隔離。這樣做不僅暴露了技術上的缺陷，也揭示了在所有關鍵決策者都無法聯繫到的情況下，管理公司的挑戰。

“”

測試的影響需要整個公司的大量協調；相比之下，混沌工程更像是對你的技術基礎設施的持續測試。由推廣，混沌工程包括編寫程序，在你的系統中不斷引入背景水平的故障，並觀察會發生什麼。有些故障可能相當大，但在大多數情況下，混沌測試工具旨在在事情失控之前恢復功能。混沌工程的目標是幫助團隊打破穩定性和可靠性的假設，幫助他們應對建立彈性的挑戰。今天，谷歌的團隊每週都會使用我們自己開發的名爲的系統進行數千次混沌測試。

這些類型的故障和負面測試對於具有足夠理論容錯能力的實時生產系統是有意義的，並且測試本身的成本和風險是可以承受的。

>>>在這次測試中，幾乎沒有人能完成任何事情，所以很多人放棄了工作，去了我們衆多咖啡館中的一家，在這樣做的過程中，我們最終對我們的咖啡館團隊發起了攻擊！

侷限性

此時（生產中）發現的任何問題都已經影響到最終用戶。

的運行成本相當高，因此我們不經常進行協作演練。當我們製造這種程度的故障時，我們實際上造成了痛苦，並對員工的績效產生了負面影響。

如果探針執行了一個可變（寫）的動作，它將修改生產的狀態。這可能導致非確定性和斷言的失敗，未來寫入能力的失敗，或用戶可見的副作用。

用戶評價

此類試驗具有以下特點：

：生產數據：生產驗證：手動和對比（度量）

’“”

基於產品的測試可以收集大量關於用戶行爲的數據。我們有幾種不同的方法來收集有關即將推出的功能的受歡迎程度和問題的指標，這爲我們提供了的替代方案：

喫自己的狗糧我們可以利用有限的推廣和實驗，將生產中的功能提供給一部分用戶使用。我們有時會和自己的員工一起這樣做（喫自己的狗糧），他們會在真實的部署環境中給我們提供寶貴的反饋。實驗在用戶不知情的情況下，將一個新的行爲作爲一個實驗提供給一部分用戶。然後，將實驗組與控制組在某種期望的指標方面進行綜合比較。例如，在，我們做了一個有限的實驗，改變了視頻加分的方式（取消了降分），只有一部分用戶看到了這個變化。這是一個對谷歌來說非常重要的方法。在加入公司後聽到的第一個故事是關於谷歌推出了一個實驗，改變了谷歌搜索中廣告的背景陰影顏色，並注意到實驗組的用戶與對照組相比，廣告點擊量明顯增加。評分員評價評分員會被告知某一特定操作的結果，並選擇哪一個更好以及原因。然後，這種反饋被用來確定一個特定的變更是正面、中性還是負面的。例如，谷歌在歷史上一直使用評分員對搜索查詢進行評估（我們已經公佈了我們給評員者的指導方針）。在某些情況下，來自該評級數據的反饋有助於確定算法更改的啓動通過不通過。評價員的評價對於像機器學習系統這樣的非確定性系統至關重要，因爲這些系統沒有明確的正確答案，只有一個更好或更差的概念。

大型測試和開發人員工作流程

’

我們已經討論了什麼是大型測試，爲什麼要做測試，什麼時候做，做多少測試，但我們還沒有說太多是誰的問題。誰來寫測試？誰來運行測試並調查故障？誰擁有這些測試？我們如何讓這一切變得可以忍受？

儘管標準的單元測試基礎設施可能不適用，但將大型測試集成到開發人員的工作流程中仍然是至關重要的。做到這一點的一個方法是確保存在預提交和提交後執行的自動化機制，即使這些機制與單元測試的機制不同。在谷歌，許多大型測試不屬於。它們不封閉、太不穩定和或資源密集。但是我們仍然需要防止它們被破壞，否則它們就不能提供任何信號，並且變得太難處理了。那麼，我們所做的就是爲這些測試建立一個單獨的提交後持續構建。我們也鼓勵在提交前運行這些測試，因爲這樣可以直接向作者提供反饋。

需要手動批准的對比測試也可以被納入這樣一個工作流程。對於預提交，在批准更改之前批准中的任何差異可能是代碼審查要求。我們有一個這樣的測試，如果提交的代碼有未解決的差異，就會自動歸檔阻斷髮布的錯誤。

在某些情況下，測試是如此之大或痛苦，以至於提交前的執行增加了太多的開發者負擔。這些測試仍然在提交後運行，並且作爲發佈過程的一部分運行。不在提交前運行這些測試的缺點是，會進入，我們需要確定罪魁禍首的變化來回滾它。但我們需要在開發人員的痛苦和所產生的變更延遲與持續構建的可靠性之間做出權衡。

編寫大型測試

雖然大型測試的結構是相當標準的，但創建這樣的測試仍然存在挑戰，特別是當團隊中有人第一次操作時。

要使寫這種測試成爲可能，最好的辦法是有明確的庫、文檔和例子。單元測試很容易寫，因爲有本地語言的支持（曾經很深奧，但現在是主流）。我們重新使用這些斷言庫進行功能集成測試，但隨着時間的推移，我們也創建了與交互的庫，用於運行差異，用於播種測試數據，以及用於協調測試工作流。

大型測試在資源和人力時間方面的維護成本較高，但不是所有的大型測試都是一樣的。對比測試受歡迎的一個原因是，它們在維護驗證步驟方面的人力成本較低。同樣，生產型的維護成本比隔離的封閉型要低。而且，由於所有這些自創的基礎設施和代碼都必須被維護，成本的節省可以是落地的。

然而，必須從整體上看待這一成本。如果手動協調差異或支持和保護生產測試的成本超過了節省的成本，那麼它將變得無效。

進行大型測試

’

我們在上面提到，我們的大型測試不適合在中進行，所以我們爲它們準備了備用的持續構建和預提交。對我們的工程師來說，最初的挑戰之一是如何運行非標準的測試，以及如何對它們進行迭代。

我們儘可能地使我們的大型測試以工程師熟悉的方式運作。我們的預提交基礎設施在運行這些測試和運行測試之前都提供了一個通用的，我們的代碼審查基礎設施顯示了這兩組結果。但許多大型測試是定製的，因此需要具體的文檔來說明如何按需運行它們。對於不熟悉的工程師來說，這可能是一個令人沮喪的原因。

加快測試進度

’

工程師不會等待緩慢的測試。測試越慢，工程師運行測試的頻率就越低，失敗後等待測試再次通過的時間就越長。

加速測試的最佳方法通常是縮小其範圍，或者將大型測試拆分爲兩個可以並行運行的小型測試。但是，您還可以使用其他一些技巧來加速更大的測試。

一些簡單的測試會使用基於時間延遲注入來等待非確定性的動作發生，這在大型測試中是很常見的。但是，這些測試沒有線程限制，並且實際生產用戶希望等待的時間儘可能少，因此最好讓測試以實際生產用戶的方式做出反應。方法包括：

在時間窗口內重複輪詢狀態轉換，以使事件以接近微秒的頻率完成。如果測試無法達到穩定狀態，你可以將其與超時值結合起來。實現一個事件處理程序。訂閱事件完成通知系統。

請注意，當運行這些測試的負載變得超載時，依賴延時和超時的測試都會開始失敗，這是因爲這些測試需要更頻繁地重新運行，進一步增加了負載。

更低的內部系統超時和延遲。生產系統通常採用分佈式部署拓撲進行配置，但可能部署在一臺機器上（或至少是一個羣集的機器）。如果在生產代碼中存在硬編碼超時或（特別是）休眠語句來解釋生產系統延遲，則應在運行測試時使其可調並減少。

優化測試構建時間。我們的的一個缺點是，大型測試的所有依賴項都是作爲輸入構建和提供的，但對於一些大型測試來說，這可能不是必需的。如果是由一個真正的測試重點的核心部分和其他一些必要的對等二進制依賴組成的，那麼可以在已知的良好版本中使用這些其他二進制文件的預構建版本。我們的構建系統（基於）不容易支持這種模式，但該方法實際上更能反映不同服務以不同版本發佈的生產。

驅除鬆散性

對於單元測試來說，鬆散性已經很糟糕了，但對於大型測試來說，它可能會使它們無法使用。一個團隊應該把消除這種測試的鬆散性視爲一個高度優先事項。但是，如何才能從這些測試中消除鬆散性呢？

最大限度地減少鬆散，首先要減少測試的範圍封閉的不會有生產或共享預發環境的各種多用戶和真實世界鬆散的風險，單機封閉的不會有分佈式的網絡和部署閃失問題。但是你可以通過測試設計和實施以及其他技術來減輕其他的鬆散性問題。在某些情況下，你需要平衡這些與測試速度。

正如使測試反應式或事件驅動可以加快它們的速度一樣，它也可以消除鬆散性。定時休眠需要超時維護，這些超時可以嵌入測試代碼中。增加系統的內部超時可以減少鬆散性，而減少內部超時可以導致鬆散性，如果系統的行爲是不確定的。這裏的關鍵是確定一個權衡（平衡），既要爲終端用戶定義一個可容忍的系統行爲（例如，我們允許的最大超時是秒），但很好地處理了不穩定的測試執行行爲。

’’’

內部系統超時的一個更大問題是，超過這些超時會導致難以分類的錯誤。生產系統通常會試圖通過優雅地方式處理可能的內部系統問題來限制終端用戶對災難性故障的暴露。例如，如果谷歌不能在給定的時間限制內提供廣告，我們不會返回，我們只是不提供廣告。但在測試運行人員看來，如果只是出現異常超時問題，廣告服務可能會被中斷。在這種情況下，重要的是使故障模式變得明顯，並使調整測試場景的此類內部超時變得容易

讓測試變得易懂

當這些測試產生的結果對運行測試的工程師來說是無法理解的時候，就很難將測試整合到開發者的工作流程中。即使是單元測試也會產生一些混亂如果我的修改破壞了你的測試，如果我一般不熟悉你的代碼，就很難理解爲什麼，但對於大型測試，這種混亂可能是無法克服的。堅定的測試必須提供一個明確的通過失敗信號，並且必須提供有意義的錯誤輸出，以幫助分類失敗的原因。需要人工調查的測試，如對比測試，需要特殊處理纔能有意義，否則在預提交期間有被跳過的風險。

“”’“”’

這在實踐中是如何運作的？一個成功的大型測試應該從失敗中獲取到信息，要做到以下幾點：

有一個明確指出失敗原因的信息最壞的情況是有一個錯誤，只是說斷言失敗和一個堆棧跟蹤。一個好的錯誤能預見到測試運行者對代碼的不熟悉，並提供一個信息來說明背景。”中，預期有個搜索結果，但得到了個。對於失敗的性能或對比測試，在輸出中應該有一個明確的解釋，說明什麼是被測量的，爲什麼該行爲被認爲是可疑的。儘量減少識別差異的根本原因所需的努力堆棧跟蹤對較大的測試沒有用，因爲調用鏈可能跨越多個進程邊界。相反，有必要在整個調用鏈中產生一個跟蹤，或者投資於能夠縮小罪魁禍首的自動化。測試應該產生某種工具來達到這個效果。例如，是谷歌使用的一個框架，將一個單一的請求與調用鏈中的所有請求相關聯，該請求的所有相關日誌都可以通過該進行關聯，以方便追蹤。提供支持和聯繫信息通過使測試的所有者和支持者易於聯繫，測試運行者應該很容易獲得幫助。

大型測試所有權

大型測試必須有記錄的所有者他們可以充分審查測試的變更，並且在測試失敗的情況下，可以依靠他們提供支持。沒有適當的所有權，測試可能成爲以下情況的受害者：

參與者修改和更新測試變得更加困難解決測試失敗需要更長的時間

而且測試也會腐爛。

“”“”

特定項目中組件的集成測試應由項目負責人負責。以功能爲中心的測試（覆蓋一組服務中特定業務功能的測試）應由“功能所有者”負責；在某些情況下，該所有者可能是負責端到端功能實現的軟件工程師；在其他情況下，可能是負責業務場景描述的產品經理或“測試工程師”。無論誰擁有該測試，都必須有權確保其整體健康，並且必須具備支持其維護的能力和這樣做的激勵。

如果以結構化的方式記錄此信息，則可以圍繞測試所有者構建自動化。我們使用的一些方法包括：

常規代碼所有權在許多情況下，大型測試是一個獨立的代碼構件，它位於代碼庫中的特定位置。在這種情況下，我們可以使用中已經存在的所有者（第章）信息來提示自動化，特定測試的所有者是測試代碼的所有者。

每個測試註釋在某些情況下，可以將多個測試方法添加到單個測試類或模塊中，並且這些測試方法中的每一個都可以有不同的特性所有者。我們使用每種語言的結構化註釋，用於記錄每種情況下的測試所有者，以便在特定測試方法失敗時，我們可以確定要聯繫的所有者。

總結

一個全面的測試套件需要大型測試，既要確保測試與被測系統的仿真度相匹配，又要解決單元測試不能充分覆蓋的問題。因爲這樣的測試必然更復雜，運行速度更慢，所以必須注意確保這樣的大型測試是正確的，良好的維護，並在必要時運行（例如在部署到生產之前）。總的來說，這種大型測試仍然必須儘可能的小（同時仍然保留仿真度），以避免開發人員的阻力。一個全面的測試策略，確定系統的風險，以及解決這些風險的大型測試，對大多數軟件項目來說是必要的。

內容提要

大型測試涵蓋了單元測試不能涵蓋的內容。大型測試是由被測系統、數據、操作和驗證組成。良好的設計包括識別風險的測試策略和緩解風險的大型測試。必須對大型測試做出額外的努力，以防止它們在開發者的工作流程中產生阻力。